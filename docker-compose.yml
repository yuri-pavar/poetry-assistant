version: '3.9'

services:
  web:
    build: .
    container_name: poetry-api
    command: uvicorn app.main:app --host 0.0.0.0 --port 8001 --reload
    volumes:
      - .:/app
    ports:
      - "8001:8001"
    depends_on:
      - postgres
      - rabbitmq
    env_file: .env

  # worker:
  #   build: .
  #   container_name: poetry-worker
  #   # command: celery -A app.celery.worker.celery_app worker --loglevel=info -Q poetry_queue
  #   command: celery -A app.celery worker --loglevel=info -Q poetry_queue
  #   environment:
  #     - PYTHONPATH=/poetry_project
  #   volumes:
  #     - .:/poetry_project
  #   depends_on:
  #     - web
  #     - rabbitmq
  #     - postgres
  #   env_file: .env

  # worker:
  #   build: .
  #   container_name: poetry-worker
  #   command: celery -A app.celery worker --loglevel=info -Q poetry_queue
  #   environment:
  #     - PYTHONPATH=/app
  #   volumes:
  #     - .:/app
  #   depends_on:
  #     - web
  #     - rabbitmq
  #     - postgres
  #   env_file: .env

  worker:
    build: .
    container_name: poetry-worker
    command: celery -A app.celery worker --loglevel=info -Q poetry_queue
    environment:
      - PYTHONPATH=/app
    volumes:
      - .:/app
    depends_on:
      - web
      - rabbitmq
      - postgres
    env_file: .env
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]


  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"

  postgres:
    image: postgres:14
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: poetry_db
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

  vllm:
    build:
      context: ./docker
      dockerfile: vllm.Dockerfile
    container_name: vllm
    ports:
      - "8000:8000"
    volumes:
      - /home/user/.cache/huggingface:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    environment:
      - MODEL_NAME=${VLLM_MODEL_NAME}
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
    #   interval: 5s
    #   timeout: 2s
    #   retries: 20

  nginx:
    image: nginx:alpine
    container_name: poetry-nginx
    ports:
      - "80:80"
    volumes:
      # - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
      # - ./docker/nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - ./docker/default.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - web
      - vllm

volumes:
  pgdata: